# ğŸ® Tic-Tac-Toe

![Tic-Tac-Toe Mockup](docs/tictactoe-mockup.png)

## Table of Contents

- [Introduction](#introduction)
    - [Project goals](#project-goals)
- [Data Model](#data-model)
    - [UML Diagram](#uml-diagram)
    - [Project Structure](#project-structure)
    - [Design](#design)
- [Features](#features)
    - [Existing features](#existing-features)
    - [AI Behavior & Strategy](#ai-behavior--strategy)
    - [Future features](#future-features)
- [Technologies](#technologies)
- [Testing](#testing)
    - [Input Validation](#input-validation)
    - [Code Validation](#code-validation)
    - [Tests result](#tests-result)
- [Bugs](#bugs)
    - [Solved Bugs](#solved-bugs)
    - [Unresolved Bugs](#unresolved-bugs)
- [Deployment](#deployment)
    - [Adding, committing and pushing code](#adding-committing-and-pushing-code)
    - [Cloning and Forking](#cloning-and-forking)
    - [Running the project locally](#running-the-project-locally)
    - [Gameplay Instructions](#gameplay-instructions)
- [Credits](#-credits)

## ğŸ“– Introduction

This is a text-based version of the classic Tic-Tac-Toe game. It is a fully interactive, terminal-based project designed with a focus on user experience, clean code architecture, and scalability. Players can compete in human vs. human or human vs. AI modes, with three different AI difficulty levels.

### Project goals

- Write clean, maintainable, and well-structured Java code.
- Design a user-friendly, readable, and engaging terminal game.
- Explore object-oriented programming principles in a practical context.
- Implement robust input validation and helpful user feedback.
- Create a visually engaging and intuitive experience â€” even in a text-based environment.

[â¬† Back to top](#table-of-contents)

## ğŸ§© Data Model

### ğŸ—ºï¸ UML Diagram

The UML diagram below was created in Lucidchart to outline the initial structure and relationships between the main components of the game. It illustrates how the core parts 
â€” including game logic, AI strategies, and player classes â€” were originally designed to interact.

While the diagram provided a solid foundation during early development, the final implementation evolved as new features and supporting classes were introduced.

![UML Diagram](docs/treirad-uml.png)

**Legend:**  
\+ public  
\- private  
â†’ Association  
-â–· Implementation (interface)

### ğŸ—‚ï¸ Project Structure

The project is organized into packages based on functionality, improving readability, maintainability, and scalability:
- app â†’ Handles game flow and user interaction.
- model â†’ Defines core data and rules.
- player â†’ Abstracts human and AI behavior.
- ai â†’ Provides interchangeable AI strategy implementations.
- util â†’ Centralizes helpers and shared logic.

```
src/
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ AiStrategy.java
â”‚   â”œâ”€â”€ Difficulty.java
â”‚   â”œâ”€â”€ HeuristicStrategy.java
â”‚   â”œâ”€â”€ MinimaxStrategy.java
â”‚   â””â”€â”€ RandomStrategy.java
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Game.java
â”‚   â””â”€â”€ Main.java
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ Board.java
â”‚   â”œâ”€â”€ Mark.java
â”‚   â””â”€â”€ Scoreboard.java
â”œâ”€â”€ player/
â”‚   â”œâ”€â”€ ComputerPlayer.java
â”‚   â”œâ”€â”€ HumanPlayer.java
â”‚   â””â”€â”€ Player.java
â””â”€â”€ util/
    â”œâ”€â”€ CellParser.java
    â”œâ”€â”€ ConsoleColors.java
    â”œâ”€â”€ ConsoleUI.java
    â”œâ”€â”€ Grid.java
    â”œâ”€â”€ Messages.java
    â””â”€â”€ NameValidator.java
```

### ğŸ¨ Design

A key design goal was to make the game as engaging and user-friendly as possible, even within a terminal environment.
Some key design decisions:
- Color usage â€“ ANSI colors highlight errors, prompts, input, and narration.
- Consistency â€“ Each player keeps the same color to clearly show turns.
- Clear formatting â€“ Output uses headings, spacing, and labels for readability.
- Helpful feedback â€“ Input errors are highlighted immediately with instructions.

[â¬† Back to top](#table-of-contents)

## âœ¨ Features

### ğŸ”§ Existing features

- Human vs Human and Human vs AI gameplay modes.
- Adjustable board size (3Ã—3 up to 10Ã—10) in Human vs Human mode.
- Three AI difficulty levels: Random, Heuristic, and Minimax.
- Robust input validation with clear error messages.
- Comprehensive scoreboard tracking wins and draws.
- Centralized message management in Messages.java for easy localization.
- ANSI-colored console output for enhanced readability and engagement.

#### ğŸ¤– AI Behavior & Strategy

| Difficulty | Strategy Class | Description |
|------------|------------------|--------------|
| **Easy** | `RandomStrategy` | Selects a random empty cell â€” simple and unpredictable. |
| **Medium** | `HeuristicStrategy` | Blocks or extends potential winning lines â€” more defensive. |
| **Hard** | `MinimaxStrategy` | Evaluates all possible future states to choose the optimal move. |

### ğŸŒŸ Future features

- Persistent player statistics across sessions.
- Monthly challenges or mini-tournaments.
- Enhanced AI logic for larger board sizes.
- Support for multiple game variants (e.g., â€œ4-in-a-rowâ€).

[â¬† Back to top](#table-of-contents)

## ğŸ› ï¸ Technologies

- Java 21 â€“ Core language and standard libraries.
- JUnit 5 â€“ Unit testing framework.
- Git â€“ Version control.
- GitHub â€“ Repository hosting and collaboration.
- IntelliJ IDEA â€“ Development environment.

[â¬† Back to top](#table-of-contents)

## ğŸ§ª Testing

Testing was performed continuously throughout the project using JUnit 5, with both manual and automated methods. This ensured correct behavior, robust edge-case handling, and system stability during refactoring.

### ğŸ›¡ï¸ Input Validation

All critical inputs (player names, board size, move coordinates) are validated before processing. Invalid input triggers clear, colored error messages and prompts for retry.

### ğŸ§° Code Validation

- All classes and methods follow SRP (Single Responsibility Principle).- All classes and methods follow SRP (Single Responsibility Principle).
- The project passes all JUnit tests without errors.
- Code follows OOP and clean-code best practices.

### ğŸ“Š Tests result:
[View all test files here](https://github.com/Linnea87/tic-tac-toe/tree/main/test)

The table below provides a detailed overview of the unit tests implemented for this project. Each test verifies key functionality to ensure that the system behaves as expected, remains stable under different scenarios, and meets quality and reliability standards.

#### `model` Package Tests

| Test Class | Description | Status |
|------------|------------|--------|
| **BoardTest** | Validates placing marks, win conditions (rows, columns, diagonals), full board detection, and invalid moves. | âœ… |
| **ScoreboardTest** | Ensures correct tracking of wins per player and handling of multiple players. | âœ… |

#### `util` Package Tests

| Test Class | Description | Status |
|------------|------------|--------|
| **NameValidatorTest** | Checks that valid and invalid names are handled correctly. | âœ… |
| **CellParserTest** | Validates and parses user input like `A1` into board positions and throws correct exceptions for invalid input. | âœ… |
| **MessagesTest** | Ensures all user-facing messages are displayed correctly and consistently. | âœ… |
| **ConsoleUITest** | Verifies formatted console output, colors, and layout helpers. | âœ… |
| **ConsoleColorsTest** | Ensures ANSI color codes are applied and rendered correctly. | âœ… |

#### `player` Package Tests

| Test Class | Description | Status |
|------------|------------|--------|
| **HumanPlayerTest** | Tests player input handling and constructor validation. | âœ… |
| **ComputerPlayerTest** | Ensures AI moves are only made in valid, empty cells. | âœ… |

#### `ai` Package Tests

| Test Class | Description | Status |
|------------|------------|--------|
| **RandomStrategyTest** | Verifies AI always selects valid empty cells. | âœ… |
| **HeuristicStrategyTest** | Ensures AI correctly blocks or extends winning lines. | âœ… |
| **MinimaxStrategyTest** | Tests minimax decision-making logic and ensures optimal moves. | âœ… |

#### `app` Package Tests

| Test Class | Description | Status |
|------------|------------|--------|
| **MenuTest** | Validates menu navigation, option selection, and user flow. | âœ… |
| **GameTest** | Full end-to-end simulation: verifies player X winning a game (including board size selection), draw scenarios, AI matches at all difficulty levels, and scoreboard + restart flow. | âœ… |

[â¬† Back to top](#table-of-contents)

## ğŸ› Bugs

### ğŸ”¨ Solved Bugs

- Fixed crash caused by invalid user input.
- Corrected cell parsing to handle out-of-range inputs.

### ğŸ Unresolved Bugs

- None known.

[â¬† Back to top](#table-of-contents)

## ğŸš€ Deployment

### ğŸ“¤ Adding, committing and pushing code

```
git add <file>
git commit -m "commit message"
git push
```

### ğŸ´ Cloning and Forking:

If you want to clone or fork this project, you can do so from my [GitHub](https://github.com/Linnea87/tic-tac-toe) repository.

#### Requirements:
- Java JDK 21 or later
- Git
- IntelliJ IDEA (or another Java IDE)

```
git clone https://github.com/Linnea87/tic-tac-toe.git
cd tic-tac-toe
```

### ğŸ’» Running the project locally

#### In IntelliJ;

```
Right-click on Main.java â†’ Run 'Main'
```

#### In terminal;
```
javac -d out src/**/*.java
java -cp out app.Main
```

### ğŸ•¹ï¸ Gameplay Instructions

Moves are entered as Column + Row, e.g. A1, B2, C3.

#### Example empty board
```
    A   B   C
1     |   |  
   ---+---+---
2     |   |  
   ---+---+---
3     |   |  
```

#### Example mid-game

```
    A   B   C
1   X | O |  
   ---+---+---
2     | X |  
   ---+---+---
3   O |   | X
```

[â¬† Back to top](#table-of-contents)

## ğŸ™Œ Credits
- Occasional debugging, code reviews, and documentation support by AI tools.
- [Carbon](https://carbon.now.sh) was used to create the terminal mockup image included in this README.
- [Lucidchart](https://www.lucidchart.com) was used to create the UML diagram.
  
[â¬† Back to top](#table-of-contents)

---

âœ¨ _Best wishes and happy coding!_

**LinnÃ©a Ternevik**


