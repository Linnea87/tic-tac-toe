# ğŸ® Tic-Tac-Toe (Text-based, Java)
_Developed as a school assignment at Folkuniversitetet._

![Tic-Tac-Toe Mockup](docs/tictactoe-mockup.png)
Tic-Tac-Toe is a two-player game for the terminal, featuring an optional computer opponent with multiple difficulty levels,  
and support for dynamic board sizes (3Ã—3 up to 10Ã—10 in Human vs Human mode).

---

## ğŸ§­ Table of Contents
- [ğŸ§© UML Diagram](#-uml-diagram)
- [ğŸ§± Project Structure](#-project-structure)
- [ğŸ¤– AI Overview](#-ai-overview)
- [âš™ï¸ Design Decisions](#-design-decisions)
- [ğŸ§ª Testing Philosophy](#-testing-philosophy)
- [ğŸ— Build & Run](#-build--run)
- [ğŸš€ Roadmap](#-roadmap)
- [ğŸ’¬ Lessons Learned](#-lessons-learned)
- [âœ¨ Credits](#-credits)

---

## ğŸ§© UML Diagram
The UML diagram below illustrates the initial architecture of the project â€” showing how the main components such as the game logic, AI strategies, and player classes were planned to interact.  
It represents the foundation of the system design, created early in development to guide implementation.  
As the project evolved, new supporting classes were added to improve structure, readability, and to better align with clean coding principles.  
The diagram below captures that original design intent:

![UML Diagram](docs/treirad-uml.png)

### Legend
\+ public  
\- private  
â†’ Association  
-â–· Implementation (interface)

[â¬† Back to top](#-table-of-contents)

---

## ğŸ§± Project Structure
The project is divided into packages for clarity and scalability:

- **ai** â†’ AI strategies (Random, Heuristic, Minimax). Also contains Difficulty enum.
- **app** â†’ Entry point and game loop (Main, Game).
- **model** â†’ Core classes (Board, Scoreboard, Mark enum).
- **player** â†’ Player interface + implementations (HumanPlayer, ComputerPlayer).
- **util** â†’ Console helpers and shared utilities:
    - `ConsoleUI` (headings, colored messages, helpers)
    - `ConsoleColors` (ANSI color codes)
    - `Messages` (centralized prompts/errors)
    - `NameValidator` (validates and formats player names)
    - `CellParser` (parses inputs like `A1` â†’ cell index)

### Why this structure?
- **Separation of concerns** â†’ Each package has its own responsibility.
- **Scalability** â†’ Easier to add new features, like new AI strategies.
- **Readability** â†’ Other developers can quickly understand the flow.

###  Directory tree
```
src/
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ AiStrategy.java
â”‚   â”œâ”€â”€ Difficulty.java
â”‚   â”œâ”€â”€ HeuristicStrategy.java
â”‚   â”œâ”€â”€ MinimaxStrategy.java
â”‚   â””â”€â”€ RandomStrategy.java
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Game.java
â”‚   â””â”€â”€ Main.java
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ Board.java
â”‚   â”œâ”€â”€ Mark.java
â”‚   â””â”€â”€ Scoreboard.java
â”œâ”€â”€ player/
â”‚   â”œâ”€â”€ ComputerPlayer.java
â”‚   â”œâ”€â”€ HumanPlayer.java
â”‚   â””â”€â”€ Player.java
â””â”€â”€ util/
    â”œâ”€â”€ CellParser.java
    â”œâ”€â”€ ConsoleColors.java
    â”œâ”€â”€ ConsoleUI.java
    â”œâ”€â”€ Messages.java
    â””â”€â”€ NameValidator.java
```
[â¬† Back to top](#-table-of-contents)

---

## ğŸ¤– AI Overview

| Difficulty | Strategy Class | Description |
|-------------|----------------|--------------|
| **Easy** | `RandomStrategy` | Picks a random empty cell. Simple and unpredictable. |
| **Medium** | `HeuristicStrategy` | Blocks or extends potential winning lines â€” more defensive. |
| **Hard** | `MinimaxStrategy` | Evaluates all possible future states to find the best outcome. |

The AI system follows the **Strategy pattern**, allowing each difficulty level to use its own logic while the game loop stays the same.  
Currently, AI mode always runs on a **3Ã—3 board**, ensuring quick and consistent decision-making.

[â¬† Back to top](#-table-of-contents)

---

## âš™ï¸ Design Decisions

Throughout the project, I focused on writing clean, modular, and testable code.  
Here are some of the key architectural and design decisions I made:

### 1. Clear Separation of Concerns
Each package (ai, app, model, player, util) has one well-defined purpose:
- `app` handles game flow and user interaction.
- `model` defines core data and rules.
- `player` abstracts human and AI behavior.
- `ai` provides interchangeable strategy implementations.
- `util` centralizes helpers and shared logic.

### 2. Strategy Pattern for AI
The AI uses the **Strategy Pattern**, allowing multiple difficulty levels to share the same interface (`AiStrategy`).  
This made it easy to plug in `Random`, `Heuristic`, or `Minimax` behavior without changing the game loop.

### 3. Single Responsibility Principle (SRP)
Each class has one clear responsibility:
- `Board` â†’ Manages game state and win logic.
- `Game` â†’ Controls the main loop.
- `Menu` â†’ Handles user input before and after a game.
- `ConsoleUI` â†’ Displays formatted messages.

### 4. Centralized Validation & Error Messages
All user-facing text (prompts and errors) are defined in `Messages.java`.  
This reduces duplication and makes future localization easy.

### 5. Testability by Design
Objects such as `Scanner` and `AiStrategy` are injected, not hardcoded.  
This makes classes modular and easy to test in isolation with JUnit.

### 6. Extensibility in Mind
The `Board` class supports dynamic sizes (3â€“10), which lays the foundation for larger board modes or â€œ4-in-a-rowâ€ expansions.

[â¬† Back to top](#-table-of-contents)

---

## ğŸ§ª Testing Philosophy

Unit tests are written with **JUnit 5**.  
The test sources live under `test/` with the same package structure as `src/`.

### Directory tree (tests)
```
test/
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ RandomStrategyTest.java
â”‚   â”œâ”€â”€ HeuristicStrategyTest.java
â”‚   â”œâ”€â”€ MinimaxStrategyTest.java
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ GameTest.java
â”‚   â”œâ”€â”€ MenuTest.java
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ BoardTest.java
â”‚   â”œâ”€â”€ ScoreboardTest.java
â”œâ”€â”€ player/
â”‚   â”œâ”€â”€ ComputerPlayerTest.java
â”‚   â”œâ”€â”€ HumanPlayerTest.java
â””â”€â”€ util/
    â”œâ”€â”€ CellParserTest.java
    â”œâ”€â”€ ConsoleUITest.java
    â”œâ”€â”€ MessagesTest.java
    â”œâ”€â”€ NameValidatorTest.java
```

### Run tests
- In IntelliJ: right-click on `test/` âœ **Run 'All Tests'**
- Or via Maven/Gradle if you add a build tool later (e.g., `mvn test`)

### Current coverage
- **BoardTest** â†’ placing marks, win conditions (row, column, diagonals), full board, invalid moves.
- **ScoreboardTest** â†’ tracking wins per player and multiple players.
- **NameValidatorTest** â†’ ensures valid/invalid names behave correctly.
- **HumanPlayerTest** â†’ tests player input and constructor validation.
- **ComputerPlayerTest** â†’ ensures AI moves only in valid, empty cells.
- **RandomStrategyTest** â†’ verifies AI always returns valid empty cells.
- **GameTest** â†’ full end-to-end simulation:
    - Player X winning a game (includes board size selection)
    - Draw scenario
    - Playing vs Computer (all difficulty levels)
    - Scoreboard and restart flow

> ğŸ’¡ *Goal: not just coverage, but confidence â€” if something breaks, tests immediately reveal where.*

[â¬† Back to top](#-table-of-contents)

---

## ğŸ— Build & Run
Standard Java project (no external dependencies). Code lives under `src/`.

### Run in IntelliJ
Right-click on `Main.java` â†’ **Run 'Main'**

### Run via terminal
```
javac -d out src/**/*.java
java -cp out app.Main
```

### How to play (input)
Enter moves in the format **Column + Row**, e.g. `A1`, `B2`, `C3`.

In Human vs Human mode, you can now choose the board size (3â€“10).
The computer opponent always plays on a standard 3Ã—3 board.

#### Empty board
```
    A   B   C
1     |   |  
   ---+---+---
2     |   |  
   ---+---+---
3     |   |  
```
#### Example mid-game
```
    A   B   C
1   X | O |  
   ---+---+---
2     | X |  
   ---+---+---
3   O |   | X
```
[â¬† Back to top](#-table-of-contents)

---

## ğŸš€ Roadmap
* âœ… Two human players (terminal)
* âœ… Win/draw detection, input validation
* âœ… Restart after game ends
* âœ… OOP structure (Board, Game, Player, Scoreboard)
* âœ… JUnit tests for Board and Scoreboard
* âœ… Names & turn prompts
* âœ… Input error handling (robust)
* âœ… Computer player (Random / Heuristic / Minimax)
* âœ… Difficulty selection (EASY / MEDIUM / HARD)
* âœ… Dynamic board size selection (3â€“10) for Human vs Human mode

### Future improvements:
-	Persistent player statistics
-	Monthly challenges or mini-tournaments
-	Enhanced AI logic for larger boards

[â¬† Back to top](#-table-of-contents)

---

## ğŸ’¬ Lessons Learned
-	Deepened understanding of object-oriented design and encapsulation.
-	Practiced test-driven development principles through iterative testing.
-	Learned to apply design patterns like Strategy and SRP effectively.
-	Improved ability to debug and refactor safely using unit tests.
-	Realized how structure and readability are key for long-term maintainability.

[â¬† Back to top](#-table-of-contents)

---

## âœ¨ Credits

### Content
All code in this project was written by LinnÃ©a Ternevik (2025).

### Code Support
- AI tools (e.g. ChatGPT) were used occasionally for debugging assistance,
code reviews, and documentation improvements.

### Media
- [Carbon](https://carbon.now.sh) was used to create the terminal mockup image included in this README.
- [Lucidchart](https://www.lucidchart.com) was used to create the UML diagram.

---

âœ¨ _Best wishes and happy coding!_

**LinnÃ©a Ternevik**

[â¬† Back to top](#-table-of-contents)

